{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f61a684-0bc7-4267-b1e7-f784607b858c",
   "metadata": {},
   "source": [
    "# <center>Genre Classification Using Extracted Audio Features</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9abdc18-04a9-4031-9320-7335e96f299e",
   "metadata": {},
   "source": [
    "<center> Levi Davis <br> ljd3frf@virginia.edu <br> CS 6501: Digital Signal Processing, Spring 2023 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41022757-c02d-48d9-bfb2-354ae63ebc10",
   "metadata": {},
   "source": [
    "# Introuction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8010f5-62fd-4c23-a207-3ddf85b48814",
   "metadata": {},
   "source": [
    "The aim of this project is to 1) analyze the effectiveness of audio features extracted from songs for genre classification, and 2) benchmark the performance of various classification models.\n",
    "\n",
    "I use the librosa package to calculate 12 distinct audio features such as Mel Frequency Cepstral Coefficients, spectral bandwidth, and tempogram ratio for each song. After extracting features, I calculate statistical measures such as mean and standard deviation for each feature. I use five statistical machine learning classification algorithms to explore which feature or feature pair most accurately predicts genre. I indentify the top individual features, feature pairs, and classifiers to create 12 final models using cross-validation to optimizatize hyperparamters. Finally, trying a different approach, I build a convulotional neural network (CNN) to classify songs by genre using slices of mel-spectrogram images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236243c3-c632-4817-a241-bf62d7d90b5e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfd66da-7d2a-4719-bd50-415c7e142cbe",
   "metadata": {},
   "source": [
    "I use data from the [Free Music Archive](https://github.com/mdeff/fma) (FMA) song dataset located on GitHub. I use the fma_small dataset, comprised of 8,000 .wav song files of 30 seconds each, with 8 balanced genres: Electronic, Experimental, Folk, Hip-Hop, Instrumental, International, Pop, and Rock. The archive contains metadata files that includes some audio features extracted using Librosa; however, I modify the provided FMA feature extraction code to calculate additional audio features and to create a complete data pipeline. I compute the following statistical measures for each feature: mean, standard deviation, minimum, maximum, median, skewness, and kurtosis. Note: most audio features are mutli-dimensional, so the calculated statistics are not single integers but rather an array or matrix. Below is an overview of the extracted audio features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a65567-4c6c-4ee1-a313-e413607954c6",
   "metadata": {},
   "source": [
    "Features computed from the raw audio waveform:\n",
    " - Tempogram Ratio: This feature captures the rhythmic content of a song by calculating the tempo and beat positions.  \n",
    " - ZCR (Zero-Crossing Rate): This feature represents the number of times a signal crosses the zero axis and captures the temporal characteristics of a song.\n",
    " \n",
    "Features computed from the Constant-Q Transform: (CQT)\n",
    " - Chroma_cqt (Constant-Q Transform): This feature represents the chromatic scale of a song and captures the pitch class distribution in each audio frame.\n",
    " - Chroma_cens (Chroma Energy Normalized Statistics): This feature also captures the pitch class distribution of a song but is more robust to variations in timbre and dynamics.\n",
    " - Tonnetz: This feature represents the tonal hierarchy of a song and captures the relationships between musical chords.\n",
    "\n",
    "Feautures computed from the Short-Time Fourier Transfrom (STFT):\n",
    " - Chroma_stft (Short-Time Fourier Transform): This feature is similar to chroma_cqt but is computed using the short-time Fourier transform.\n",
    " - RMS (Root Mean Square): This feature represents the energy of a signal and captures the overall loudness of a song.\n",
    " - Spectral Bandwidth: This feature represents the bandwidth of a signal and captures the spread of frequencies in each audio frame.\n",
    " - Spectral Centroid: This feature represents the center of mass of the frequency distribution in each audio frame and captures the \"brightness\" of a song.\n",
    " - Spectral Contrast: This feature captures the difference in spectral energy between adjacent frequency bands and provides information about the spectral texture of a song.\n",
    " - Spectral Rolloff: This feature represents the frequency below which a specified percentage of the total spectral energy lies.\n",
    " - Tempogram Ratio: This feature captures the rhythmic content of a song by calculating the tempo and beat positions.\n",
    " \n",
    "Feature computed from mel-sectrograms (using STFT):\n",
    "  - MFCC (Mel-Frequency Cepstral Coefficients): This feature represents the spectral envelope of a song and captures the variations in timbre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a10607-5fb1-4bcc-a3fe-4f1501537c63",
   "metadata": {},
   "source": [
    "## ML classification algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b26d12-f8cd-4860-9279-709b0c0dda62",
   "metadata": {},
   "source": [
    "I select five popular statistical machine learning algorithms to serve as benchmarks for genre classification. Using multiple algorithms allows me to calculate an average score over all models to explore the performance of different audio features. Additionally, by averaging model accuracy scores across all audio features I can identify which algorithms preform best for this problem. Below are short descriptions of each classification algorithm.\n",
    "  \n",
    "    Support Vector Classification (SVC) is a powerful algorithm that uses a kernel function to transform the input data into a higher-dimensional space, which allows it to separate nonlinearly separable data. Then it finds the optimal hyperplane to separate data points into different classes. It does this by maximizing the margin between the hyperplane and the closest data points. Despite its high accuracy and ability to handle high-dimensional data, SVC can become computationally expensive and slow with large datasets.\n",
    "\n",
    "    Random Forest Classifier: Random Forest Classifier is an ensemble learning algorithm that creates multiple decision trees and combines their results to make a final prediction. It is based on the bagging method, which randomly selects a subset of features and data points to train each tree, reducing overfitting and improving generalization. The final prediction is made by aggregating the predictions of all trees. The algorithm is known for its ability to handle high-dimensional data, feature selection, and reducing overfitting. The runtime of the model is typically faster than other ensemble methods, such as boosting algorithms.\n",
    "\n",
    "    K-Nearest Neighbors Classifier: K-Nearest Neighbors Classifier is a non-parametric method that classifies new data points based on the majority class of the K nearest training examples. It is based on the assumption that similar data points are likely to belong to the same class. The choice of K affects the bias-variance trade-off of the model: a smaller K leads to a high variance and low bias, while a larger K leads to a low variance and high bias. The main disadvantage of this algorithm is that it is sensitive to the choice of K and can become computationally expensive for large datasets.\n",
    "\n",
    "    Decision Tree Classifier: Decision Tree Classifier is a simple and intuitive classification algorithm that works by creating a tree-like structure that represents the decision-making process. The algorithm recursively partitions the feature space into subsets based on the value of each feature and assigns a class to each subset based on the majority class of the training examples. The complexity of the model depends on the depth and width of the decision tree, and it can become slow when dealing with large datasets. The main advantage of this algorithm is that it can handle nonlinear relationships between the input features and the output classes.\n",
    "\n",
    "    Gradient Boosting Classifier: Gradient Boosting Classifier is an ensemble learning algorithm that combines multiple weak classifiers to create a strong classifier. It is based on the boosting method, which iteratively adds decision trees to the model and adjusts the weights of the data points based on the errors made in the previous iteration. The algorithm is known for its ability to handle complex datasets with high accuracy. However, it can become computationally expensive for large datasets and may require a longer runtime than other algorithms.\n",
    "\n",
    "In summation, the performance and processing time of each machine learning model depends on several factors, such as the size and intricacy of the selected features, the selected hyperparameters, and the precise implementation of the algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cab154-1f7e-461f-843e-46831388d240",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23103f4f-1d96-4e8a-93b5-5707fb65c160",
   "metadata": {},
   "source": [
    "First, I explore the effectivenss of various audio features and pinpoint the most effective audio features and classifeirs and then build final models with hyperparameter tuning.  \n",
    "\n",
    "\n",
    "Essientitally, the modeling part of this project is split into three phases. The first phase consists of 5 five classification models paired with all 12 individual features and all combinations of feature pairs - 60 single feature models and 330 two feature models. This two-dimensional (multiple algorithms and multiple features) exploration serves as an informal cross-validation process, which allows for a broad analysis of combinations of features and classification algorithms. For the second phase, I select the top two classification algorithms, the top two single features, and the top four feature pairs - totaling to 12 unqiue models - and for each model I optimize hyperparameters using 5-fold cross-validation. In phase three I implement the CNN model and show to best recorded model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a341f9a-77a6-45d2-9c4d-2c7e7e476950",
   "metadata": {},
   "source": [
    "## Phase one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8d68c-14ff-435d-918f-70a859e3f022",
   "metadata": {},
   "source": [
    "Hyperparameter optimization is not employed at this phase, and instead I use the default values in Sklearn. While this may not be the recommended course of action to procure an optiamally performing model, it is acceptable for this phase since all models utilize the same dataset and the purpose is to gather benchmark scores. Each model has an accuracy score for each feature or feature combination. Consequently, I can average accross models for each feature to obtain an average feature score, as well as average across features to obtain an average model score. While not a contributing factor for feature selection or algorithm selection in this project, I record the runtime of each model (shown in seconds)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be5c35f-be90-4280-8484-8d77de3c2e55",
   "metadata": {},
   "source": [
    "### Single Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187a3256-fbe2-471c-bfaa-155edc58e210",
   "metadata": {},
   "source": [
    "First, I create a seperate model for each distinct combination of classifier and the computed statisitcs for each feature (mean, std, skew, etc.), resulting in 60 models. Below I show the top 10 perfroming models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6e2221-12d5-4a57-8712-b256b69678be",
   "metadata": {},
   "source": [
    "![My Images](Images/single_feature_table_head.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e26931-66a8-49b8-8e23-c95a7fccad3d",
   "metadata": {},
   "source": [
    "Next, I group by classifier to get an average accuracy score for each feature, and subsequently group by feature to get an avergae accuracy score for each classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fc1655-46f0-4820-8bd9-eb64c09a60c3",
   "metadata": {},
   "source": [
    "![My Image](Images/single_feature_table_features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0a68a-2439-423c-b39e-a51801284f3d",
   "metadata": {},
   "source": [
    "![My Image](Images/single_feature_table_algos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1825a-cc76-4503-a0f9-b15ec268a174",
   "metadata": {},
   "source": [
    "These results show that mfcc is the best prediciting feature by an average of 8%, followed by spectral contrast which is 7% better than the third best feature. The Random Forest and Gradient Boosting classifiers have extremely similar average accuracies, SVC falls 6% below, and finally KNN and Decision Tree have significantly lower scores. It's worth noting the average duration of these algoorithms - Random Forest and Gradient Boosting have the same accuracies yet Random Forest runs 20x faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca32393-9b1e-4f81-b7e0-d337dbef19b7",
   "metadata": {},
   "source": [
    "### Two features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e4fcdc-bf0a-4147-bf82-f74bbcd2462e",
   "metadata": {},
   "source": [
    "Next, I use all possible combinations of two features to explore if expanding the feature space will result in greater model performance. Below are the top 10 performing feature combinations. These top 10 performing models all out-score the top single-feature model, yet only by about 2%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91d6c43-164c-480a-b8b8-47749c6afeab",
   "metadata": {},
   "source": [
    "![My Image](Images/two_feature_table_head.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9762a23-ba41-4ec0-899a-fba90c321310",
   "metadata": {},
   "source": [
    "Again, I group by classifier to get an average accuracy score for each feature pair, and subsequently group by feature pair to get an avergae accuracy score for each classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc08cc-81c4-4e91-96f6-e9df85215e1d",
   "metadata": {},
   "source": [
    "![My Image](Images/two_feature_table_features.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac138a-2812-4501-a1cb-1378694b5f0e",
   "metadata": {},
   "source": [
    "![My Image](Images/two_feature_table_algos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd9d6a-570d-4b46-a084-967a780e7ea0",
   "metadata": {},
   "source": [
    "The top 10 feature pairs all include mfcc which is clearly the best audio feature for this pr. The top feature pair model (mfcc and spectral constrast) scores 48%, 2% higher than the top single feature model (mfcc). Having two features increases average performance by classifier, boosting the average accuracies by 8% for the top two algorithms; however, this increase doesn't matter much in terms of choosing the best feature - it just demonstates that using two random features will achieve better accuracy than using one feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd519f0a-e25d-4ee3-88aa-112bbc144dbc",
   "metadata": {},
   "source": [
    "### All Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82a4812-13c8-4c59-bd38-5cd45518d77a",
   "metadata": {},
   "source": [
    "I create models using all features to examine if group effects will boost performance. Adding all features generates higher accuracies for all algorithms. Gradient Boosting scores an average of 3% higher than the best two feature model and almost 6% better than the best single feature model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce4f00e-2427-4ea4-a04a-44f2bb172c4f",
   "metadata": {},
   "source": [
    "![My Image](Images/all_feature_table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fb7f4c-7c5a-4981-b887-b3fa32ad5c98",
   "metadata": {},
   "source": [
    "## Round Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35589d97-251f-45c1-919f-099699bc3976",
   "metadata": {},
   "source": [
    "The two best classification algorithms are Gradient Boosting and Random Forest, the two best individual features are mfcc ad spectral contrast, and the four best feature pairs are mfcc/spectral_contrast, mfcc/chroma_cqt, mfcc/zcr, and mfcc/tempogram_ratio. I use 5-fold cross-validation to automatically optimize hyperparameters of each model and record the test accuracy of each final model. Duration includes the cross-validation time and the final model fit time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809debd9-6b9f-4d31-ad04-78b60897c89d",
   "metadata": {},
   "source": [
    "![My Image](Images/tm__table.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40932d01-b90b-4178-bed5-1e3d00f509de",
   "metadata": {},
   "source": [
    "The results of the models with tuned hyperparameters are underwhelming - all models have extremely similar test accuracies compared to the same model without hyperparamter optimization. Classifing music genre solely from a couple extracted features is no simple task, and 54% accuracy using 'simple' statistical algorithms is respectable compared to randomly guessing (12.5%). Nevertheless, I am not quite satisfied and now turn to deep learning. Instead of using statisical measures of extracted audio features as input, I will use Mel-spectrogram images as input into a convolutional neural network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f7cbd-dfb9-44f1-905c-8366e5cee784",
   "metadata": {},
   "source": [
    "I use the Librosa package to make the Mel-spectrograms, using n_mels = 128 and max frequency = 8000, and clip each image into 3-sec slices. Each resulting image is sized 256 x 256 (although I reszie down to 128x128 becuase the larger size offered no boost in accuracy and exceptionally slowed down training. Shown below is the CNN architeture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff486a03-4d66-4adc-b345-a482a6fab3a1",
   "metadata": {},
   "source": [
    "![My Image](Images/model_arch.png)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ff4dc-d913-4fdc-b2c7-23cc9855ff5b",
   "metadata": {},
   "source": [
    "I spent awhile fidgeting with model archetecture and hyperparamters, but here I show the final model trained for 60 epochs with the following parameters; batch_size=128, validation split=.3, and a custom learning rate that starts at .001 and decreases by a factor of 0.5 every 10 epochs. The final test accuracy is .7249, and below are plots showing training/validatiion accuracy and loss metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b5695-6e39-438c-b92b-198b0df3b4f5",
   "metadata": {},
   "source": [
    "![My Image](Images/model_test_accuracy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e378e8a3-b661-41e3-b823-d297a7a8c6fd",
   "metadata": {},
   "source": [
    "![My Image](Images/model_history.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224a43c-4400-476a-bfca-ac3aa3d634bf",
   "metadata": {},
   "source": [
    "The CNN model surpasses the top statistical machine learning model by about 15%, well worth the trade-off of more data pre-processing and longer training time. For future work, I would experiment with altering the CNN architecture and hyperparameters along with applying transformations to the image data. It would also be intersting to create a mixed model classifier by combing the CNN model with a Gradient Boosting or Random Forest model trained with all statisical measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0420ef2-d893-4cb0-ad31-7e47ee8a864b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a9a08-f2c4-409d-ba30-5ad520646a98",
   "metadata": {},
   "source": [
    "I explored various types of input data and algorithms for classifing songs by music genre. I first extracted 12 audio features and computed 7 statistical measures for each feature. I choose five statisical machine learning classification algorithms to create models for each feature, possible pair of features, and all features. From these results, I conclude that mfcc is by far the best feature, and spectral contrast is a strong second. For the classifiers, Gradient Boosting and Random Forest tie for first place, significantly ouperforming the other three models. Finally, I used Mel-spectrograms as input to a convolutional neural network which had a final test acccuracy of 72.72%. Compared to the top-performing statisitical model, the CNN model significantly out-performs the best non-neural network algorithm, Gradient Boosting trained on all 12 features, which scored 57.38%. This project explores the efficacy of extracted audio features for classifing music genre, and demonstrates how deep learning methods can significantly boost performance for signal processing problems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
